{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization of Complex Agro-Environmental Data\n",
    "---\n",
    "## Non-parametric hypothesis testing\n",
    "\n",
    "Here, some examples of application of the most commonly used non-parametric methods are shown, using simulated data.\n",
    "\n",
    "##### Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import scikit_posthocs as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulate populations (N = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the random number generator\n",
    "np.random.seed(24)\n",
    "# generate univariate observations\n",
    "pop1 = np.random.exponential(50,100000)\n",
    "pop2 = np.random.normal(50,25,100000)\n",
    "pop3 = np.random.exponential(50, 100000)\n",
    "pop4 = np.random.exponential(100, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med1, med2 = round(np.median(pop1), 3), round(np.median(pop2), 3)\n",
    "print(med1, med2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric two-sample tests\n",
    "#### Kolmogorov-smirnov test\n",
    "\n",
    "This is a very particular type of non-parametric hypothesis testing which is based on the difference between two Empirical Cumulative Distribution Funtion (ECDF), and can be used as a single sample test to check if a given sample follows some specific theoretical distribution (e.g. normal) or to test if two samples are drawn from populations with equal probability distributions.\n",
    "\n",
    "1. Define H0 : The two samples are drawn from populations with equal distributions\n",
    "2. Take sample from populations pop1 and pop2 - use the same as previous example\n",
    "3. Check assumptions (e.g. test for homeogeneity used in the parametric hypothesis testing examples)\n",
    "3. Compute the statistic and check *p-value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random samples from data (n=30)\n",
    "np.random.seed(123)\n",
    "sample1 = np.random.choice(pop1, 30)\n",
    "sample2 = np.random.choice(pop2, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using raincloud plots to compare samples\n",
    "\n",
    "1. With `ptitprince` (to install try `pip install ptitprince`)\n",
    "\n",
    "Reference: https://wellcomeopenresearch.org/articles/4-63\n",
    "\n",
    "github: https://github.com/RainCloudPlots/RainCloudPlots.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "import ptitprince as pt\n",
    "\n",
    "# Convert samples to a DataFrame with a grouping column:\n",
    "df = pd.DataFrame({'group': np.repeat(['sample1', 'sample2'], 30),\n",
    "                   'values': np.concatenate((sample1, sample2))})\n",
    "\n",
    "# run raincloud plots\n",
    "plt.figure(figsize = (7,4))\n",
    "pt.RainCloud(x = 'group', y = 'values', data=df, palette = \"Set2\", bw = .3, cut=1,\n",
    "                 width_viol = .6, width_box = 0.1, orient = \"h\", move = 0.15, offset=0) # mov - moves the rain below the boxplot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Without `ptitprince`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run raincloud plots without ptitprince\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Create a list of colors for the boxplots based on the number of features you have\n",
    "boxplots_colors = ['firebrick', 'seagreen']\n",
    "\n",
    "# Boxplot data\n",
    "bp = ax.boxplot([sample1, sample2] , patch_artist = True, vert = False)\n",
    "\n",
    "# Change to the desired color and add transparency\n",
    "for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.4)\n",
    "\n",
    "# Create a list of colors for the violin plots based on the number of features you have\n",
    "violin_colors = ['firebrick', 'seagreen']\n",
    "\n",
    "# Violinplot data\n",
    "vp = ax.violinplot([sample1, sample2], points=500, \n",
    "                bw_method = 0.3, # defines how the KDE fits the data\n",
    "                widths = 0.6, # sets the width of the violin\n",
    "                showmeans=False, showextrema=False, showmedians=False, vert=False)\n",
    "\n",
    "for idx, b in enumerate(vp['bodies']):\n",
    "    # Get the center of the plot\n",
    "    m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "    # Modify it so we only see the upper half of the violin plot\n",
    "    b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx+1, idx+2)\n",
    "    # Change to the desired color\n",
    "    b.set_color(violin_colors[idx])\n",
    "\n",
    "# Create a list of colors for the scatter plots based on the number of features you have\n",
    "scatter_colors = ['firebrick', 'seagreen']\n",
    "\n",
    "# Scatterplot data\n",
    "for idx, features in enumerate([sample1, sample2]):\n",
    "    # Add jitter effect so the features do not overlap on the y-axis\n",
    "    y = np.full(len(features), idx + .8)\n",
    "    idxs = np.arange(len(y))\n",
    "    out = y.astype(float)\n",
    "    out.flat[idxs] += np.random.uniform(low=-.05, high=.05, size=len(idxs))\n",
    "    y = out\n",
    "    plt.scatter(features, y, s=3, c=scatter_colors[idx])\n",
    "\n",
    "plt.yticks(np.arange(1,3,1), ['Sample 1', 'Sample 2'])  # Set text labels.\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the test\n",
    "stat, p = sts.ks_2samp(sample1, sample2)\n",
    "print('stat=%.3f, p-value=%.3f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney U Test (or Wilcoxon rank sum test) - two-tailed test\n",
    "\n",
    "This is a rank-based hyporthesis testing that compares the sum of ranks between two samples to infer differences in the central tendency (in this case it is interpreted as comparing medians).\n",
    "\n",
    "H0 : The two samples are drawn from populations with equal medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the medians\n",
    "med1, med2 = np.median(sample1), np.median(sample2)\n",
    "print('median of sample 1 = %.3f' % med1)\n",
    "print('median of sample 2 = %.3f' % med2)\n",
    "# Compute the test\n",
    "stat, p = sts.mannwhitneyu(sample1, sample2, alternative='two-sided')\n",
    "print('stat=%.3f, p-value=%.3f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney U Test (or Wilcoxon rank sum test) - one-tailed test\n",
    "\n",
    "H0 : Population 1 has a median > or = to Population 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the medians\n",
    "med1, med2 = np.median(sample1), np.median(sample2)\n",
    "print('median of sample 1 = %.3f' % med1)\n",
    "print('median of sample 2 = %.3f' % med2)\n",
    "# Compute the test\n",
    "stat, p = sts.mannwhitneyu(sample2, sample1, alternative='greater')\n",
    "print('stat=%.3f, p-value=%.3f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon signed rank test (paired)\n",
    "\n",
    "This is similar to the former method but assuming that observations between groups are matched (e.g. two measures taken in the same locations).\n",
    "\n",
    "H0 : The two samples are drawn from populations with equal medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = sts.wilcoxon(sample1, sample2)\n",
    "print('stat=%.3f, p-value=%.3f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric multiple sample tests\n",
    "#### Kruskal-Wallis test\n",
    "\n",
    "This is the non-parametric equivalent to the ANOVA and it is also based on the sum of ranks.\n",
    "\n",
    "1. Define H0 : The samples are drawn from populations with equal medians\n",
    "2. Take sample from populations (pop1 and pop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take random samples from data (n=20)\n",
    "\n",
    "np.random.seed(24)\n",
    "sample1 = np.random.choice(list(pop1), 50)\n",
    "sample2 = np.random.choice(list(pop2), 50)\n",
    "sample3 = np.random.choice(list(pop3), 50)\n",
    "sample4 = np.random.choice(list(pop4), 50)\n",
    "sns.kdeplot(sample1, label='Pop1')\n",
    "sns.kdeplot(sample2, label='Pop2')\n",
    "sns.kdeplot(sample3, label='Pop3')\n",
    "sns.kdeplot(sample4, label='Pop4')\n",
    "plt.legend(frameon=False, loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Compute the statistic and check the *p-value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the medians\n",
    "med1, med2, med3, med4 = np.median(sample1), np.median(sample2), np.median(sample3), np.median(sample4)\n",
    "print('median of sample 1 = %.3f' % med1)\n",
    "print('median of sample 2 = %.3f' % med2)\n",
    "print('median of sample 3 = %.3f' % med3)\n",
    "print('median of sample 4 = %.3f' % med4)\n",
    "# Compute the test\n",
    "stat, p = sts.kruskal(sample1, sample2, sample3, sample4)\n",
    "print('F-statistics=%.3f, p=%.6f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dunn's test (multiple comparisons)\n",
    "\n",
    "The Dunn's test is a non-parametric multiple comparison test to check which pairs of groups differ when a Kruskal-wallis test (or Friedman test) rejects the null hypothesis. It is implemented in the scikit-posthocs module (you may need to install: run `pip install scikit-posthocs` in the CLI terminal).\n",
    "\n",
    "H0 : The samples are drawn from populations with equal medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a list with samples\n",
    "list_sample = [sample1, sample2, sample2, sample4]\n",
    "sp.posthoc_dunn(list_sample, p_adjust = 'bonferroni') # the correction for multiple comparisons is based on the bonferroni's correction.\n",
    "# the output is a matrix of p-values for each pair of groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman test\n",
    "\n",
    "This is the non-parametric equivalent of a repeated measures ANOVA. It is implemented in statsmodels. \n",
    "\n",
    "H0 : The samples are drawn from populations with equal medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data - Ex: Measurements (crop production) taken in two times for three experimental plots with different treatments\n",
    "\n",
    "# Take random samples from sample1 (n=30)\n",
    "\n",
    "plot = np.repeat([1, 2, 3], 30)\n",
    "\n",
    "time = np.concatenate((np.repeat([1, 2], 15), np.repeat([1, 2], 15), np.repeat([1, 2], 15)))\n",
    "\n",
    "np.random.seed(123)\n",
    "time1 = np.random.choice(pop1, 30)\n",
    "time2 = np.random.choice(pop1, 30)\n",
    "time3 = np.random.choice(pop1, 30)\n",
    "values = np.concatenate((time1, time2, time3))\n",
    "\n",
    "df3 = pd.DataFrame({'plot': plot,\n",
    "                   'time': time,\n",
    "                   'crop_production': values})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raincloud plot\n",
    "ax=pt.RainCloud(x = 'plot', y = 'crop_production', hue = 'time', data = df3, palette = 'Set2', bw = .3, width_viol = .7,\n",
    "                orient = \"h\" , alpha = .65, dodge = True, pointplot = True, move = .2, offset=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = sts.friedmanchisquare(df3['crop_production'][0:30], \n",
    "                                df3['crop_production'][30:60], \n",
    "                                df3['crop_production'][60:90])\n",
    "print('Statistic=%.3f, p=%.6f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for categorical variables\n",
    "\n",
    "#### Chi-Square Test of Independence\n",
    "\n",
    "A Chi-Square Test of Independence is used to determine whether or not there is a significant association between two categorical variables.\n",
    "\n",
    "H0: The two variables are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data contingency table (counts for each class combination of two categorical variables, \n",
    "# for ex: treatment in columns (5 treatments) vs. success of treatment (success/unsuccess) in rows)\n",
    "data = [[30, 90, 50, 60, 10],\n",
    "        [70, 10, 50, 40, 90]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an aluvial (or Sankey) diagram to visualize a contingency table\n",
    "# check more here: https://plotly.com/python/sankey-diagram/\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    # define nodes:\n",
    "    node = dict(pad = 20,thickness = 20, line = dict(color = \"black\", width = 0.5), \n",
    "    label = [\"Treatment 1\", \"Treatment 2\", \"Treatment 3\", \"Treatment 4\", \"Treatment 5\", \"Success\", \"Unsuccess\"],\n",
    "    color = ['#a6cee3','#fdbf6f','#fb9a99', '#79c167', '#c478a9', '#789dc4', '#d95f59']\n",
    "    ),\n",
    "    # defines links between nodes:\n",
    "    link = dict(\n",
    "      source = [0, 0, 1, 1, 2, 2, 3, 3, 4, 4], # indices correspond to source nodes (treatments 1 to 5)\n",
    "      target = [5, 6, 5, 6, 5, 6, 5, 6, 5, 6], # Success, unsuccess\n",
    "      value = [30, 70, 90, 10, 50, 50, 60, 40, 10, 90], # proportions (%) to each target\n",
    "      color = ['#a6cee3', '#a6cee3', '#fdbf6f', '#fdbf6f','#fb9a99', '#fb9a99', '#79c167', '#79c167', '#c478a9', '#c478a9']\n",
    "  ))])\n",
    "\n",
    "# set figure size and aspect ratio\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=700,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test\n",
    "stat, p, df, expected_freq = sts.chi2_contingency(data)\n",
    "print('Statistics=%.3f, p=%.6f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the success is dependent on the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine the treatment was success was totally independent from the treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[30, 30, 30, 30, 30],\n",
    "        [30, 30, 30, 30, 30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an aluvial (or Sankey) diagram to visualize a contingency table\n",
    "# check more here: https://plotly.com/python/sankey-diagram/\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    # define nodes:\n",
    "    node = dict(pad = 20,thickness = 20, line = dict(color = \"black\", width = 0.5), \n",
    "    label = [\"Treatment 1\", \"Treatment 2\", \"Treatment 3\", \"Treatment 4\", \"Treatment 5\", \"Success\", \"Unsuccess\"],\n",
    "    color = ['#a6cee3','#fdbf6f','#fb9a99', '#79c167', '#c478a9', '#789dc4', '#d95f59']\n",
    "    ),\n",
    "    # defines links between nodes:\n",
    "    link = dict(\n",
    "      source = [0, 0, 1, 1, 2, 2, 3, 3, 4, 4], # indices correspond to source nodes (treatments 1 to 5)\n",
    "      target = [5, 6, 5, 6, 5, 6, 5, 6, 5, 6],# Success, unsuccess\n",
    "      value = [30, 30, 30, 30, 30, 30, 30, 30, 30, 30], # proportions (%) to each target\n",
    "      color = ['#a6cee3', '#a6cee3', '#fdbf6f', '#fdbf6f','#fb9a99', '#fb9a99', '#79c167', '#79c167', '#c478a9', '#c478a9']\n",
    "  ))])\n",
    "\n",
    "# set figure size and aspect ratio\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=700,\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test\n",
    "stat, p, df, expected_freq = sts.chi2_contingency(data)\n",
    "print('Statistics=%.3f, p=%.6f' % (stat, p))\n",
    "alpha=0.05\n",
    "if p > alpha:\n",
    " print('fail to reject H0. Rejecting H0 has an error probability >0.05')\n",
    "else:\n",
    " print('reject H0 with an error probability <0.05)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
